% -*- latex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Parallel Programming in MPI and OpenMP'
%%%% by Victor Eijkhout, copyright 2022
%%%%
%%%% ompcpp_course.tex : course in C++ aspects of OpenMP
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,headernav]{beamer}

\beamertemplatenavigationsymbolsempty
\usetheme{Madrid}%{Montpellier}
\usecolortheme{seahorse}
\setcounter{tocdepth}{1}
%% \AtBeginSection[]
%% {
%%   \begin{frame}
%%     \frametitle{Table of Contents}
%%     \tableofcontents[currentsection]
%%   \end{frame}
%% }

%Global Background must be put in preamble
%\usebackgroundtemplate{\includegraphics[width=\paperwidth,height=\paperheight]{newton.jpg}}

\setbeamertemplate{footline}{\hskip1em Eijkhout: OMP C++\hfill
  \hbox to 0in {\hss \includegraphics[scale=.1]{tacclogonew}}%
  \hbox to 0in {\hss \arabic{page}\hskip 1in}}

\usepackage{morewrites}

\input commonmacs
\input acromacs
\input slidemacs
\input coursemacs
\input listingmacs
\input snippetmacs

\newcounter{tacc}
\specialcomment{tacc}{\stepcounter{tacc}\def\CommentCutFile{tacc\arabic{tacc}.cut}}{}

\begin{document}
\parskip=10pt plus 5pt minus 3pt

\title{Using OpenMP from C++}
\author{Victor Eijkhout}
\date{} %{SSiASC 2016}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Justification}
  OpenMP has the opportunity to exploit features of modern~C++
  that are not present in C.
  In this course we will explore
  range-based iteration,
  differences in treatment between vectors and arrays,
  and various sophisticated reduction schemes.
\end{frame}

\sectionframe{Basic stuff}

\begin{numberedframe}{Output streams in parallel}
  \input{cppnote-output-streams-in-parallel.cut}
\end{numberedframe}

\begin{numberedframe}{Parallel regions in lambdas}
  \input{cppnote-parallel-regions-in-lambdas.cut}
\end{numberedframe}

\begin{numberedframe}{Dynamic scope for class methods}
  \input{cppnote-dynamic-scope-for-class-methods.cut}
\end{numberedframe}

\begin{numberedframe}{Vectors are copied, unlike arrays, 1}
  %% \input{cppnote-vectors-are-copied,-unlike-arrays.cut}
  C arrays: private pointer, but shared array:
  %
  \csnippetwithoutput{privatepointer}{examples/omp/c}{pointarray}
\end{numberedframe}

\begin{numberedframe}{Vectors are copied, unlike arrays, 2}
  C++ vectors: copy constructor also copies data:
  %
  \cxxsnippetwithoutput{privatevector}{examples/omp/cxx}{privvector}
\end{numberedframe}

\sectionframe{Parallel loops}

\begin{numberedframe}{Range syntax}
  \input{cppnote-range-syntax.cut}
\end{numberedframe}

\begin{numberedframe}{Custom iterators, 1}
  OpenMP can parallelize any range-based loop with a random-access iterator.
  \begin{multicols}{2}
    Class:
    \cxxverbatimsnippet{classwithiter}
    \columnbreak
    Main:
    \cxxverbatimsnippet{ompcustompar}    
  \end{multicols}
  %%  \input{cppnote-custom-iterators.cut}
\end{numberedframe}

\begin{numberedframe}{Custom iterators, 2}
  Required iterator methods:
  \cxxverbatimsnippet{omprandaccess}  
\end{numberedframe}

\sectionframe{Reductions}

\begin{numberedframe}{Reductions on vectors}
  \input{cppnote-reductions-on-vectors.cut}
\end{numberedframe}

\begin{numberedframe}{Reduction on class objects}
  \input{cppnote-reduction-on-class-objects.cut}
\end{numberedframe}

\begin{numberedframe}{reduction illustrated}
  \label{fig:omp-reduct}

  Reduction of four items on two threads, taking into account
  initial values.
  \includegraphics[scale=.1]{omp-reduct}
\end{numberedframe}

\begin{numberedframe}{Reduction over iterators}
  \input{cppnote-reduction-over-iterators.cut}
\end{numberedframe}

\begin{numberedframe}{User-defined reductions, syntax}
  \begin{lstlisting}
    #pragma omp declare reduction 
    ( identifier : typelist : combiner )
    [initializer(initializer-expression)]
  \end{lstlisting}
\end{numberedframe}

\begin{numberedframe}{Lambda expressions in declared reductions}
  \input{cppnote-lambda-expressions-in-declared-reductions.cut}
\end{numberedframe}

%% \begin{numberedframe}{Example: reduction over a map}
%%   \input{cppnote-example:-reduction-over-a-map.cut}
%% \end{numberedframe}

\begin{numberedframe}{Example category: histograms}
  \begin{lstlisting}
    for ( auto e : some_range )
      histogram[ value(e)]++;
  \end{lstlisting}
  Collisions are possible, but unlikely, so critical section is very inefficient
\end{numberedframe}

\begin{numberedframe}{Histogram: intended main program}
  \cxxverbatimsnippet{ompbinreduce}
  Q: why does the \lstinline{inc} not have to be atomic?
\end{numberedframe}

\begin{numberedframe}{Histogram: reduction operator}
  \cxxverbatimsnippet{ompbincounter}
\end{numberedframe}

\begin{numberedframe}{Example category: list filtering}
The sequential code is as follows:
\begin{lstlisting}
vector<int> data(100);
// fil the data
vector<int> filtered;
for ( auto e : data ) {
  if ( f(e) )
    filtered.push_back(e);
}
\end{lstlisting}
\end{numberedframe}

\begin{numberedframe}{List filtering, solution 1}
  Let each thread have a local array,
  and then to concatenate these:
\begin{lstlisting}
#pragma omp parallel
{
  vector<int> local;
# pragma omp for
  for ( auto e : data )
    if ( f(e) ) local.push_back(e);
  filtered += local;
}
\end{lstlisting}
where we have used an append operation on vectors:
\cxxverbatimsnippet{cppvectorplusis}
\end{numberedframe}

\begin{numberedframe}{List filtering, not quite solution 2}
We could use the plus-is operation to declare a reduction:
\cxxverbatimsnippet{cppvectorplusreduct}

Problem: OpenMP reductions can not be declared non-commutative,
so the contributions from the threads
may not appear in order.

\cxxsnippetwithoutput{cppvectordoreduct}{code/omp/cxx}{filterreduct}
\end{numberedframe}

\begin{numberedframe}{List filtering, task-based solution}
With a task it becomes possible to have a spin-wait loop:
\cxxsnippetwithoutput{cppvectordotask}{code/omp/cxx}{filtertask}
\end{numberedframe}

\begin{numberedframe}{Templated reductions}
  \input{cppnote-templated-reductions.cut}
\end{numberedframe}

\sectionframe{More topics}

\begin{numberedframe}{Threadprivate random number generators}
  \input{cppnote-threadprivate-random-number-generators.cut}
\end{numberedframe}

\begin{numberedframe}{Uninitialized containers}
  Multi-socket systems:\\
  parallel initialization instantiates pages on sockets:\\
  `first touch'
  \begin{lstlisting}
    double *x = (double*)malloc( N*sizeof(double));
    #pragma omp parallel for
    for (int i=0; i<N; i++)
      x[i] = f(i);
  \end{lstlisting}
  This does not work with
  \begin{lstlisting}
    std::vector<double> x(N);
    for ( ... same loop ... )
  \end{lstlisting}
  because of value initialization.
\end{numberedframe}

\begin{numberedframe}{Uninitialized containers, 2}
  Trick to create a vector of uninitialized data:
  %
  \cxxverbatimsnippet{cppuninitial}
  %
  so that we can create vectors that behave normally:
  %
  \cxxverbatimsnippet{cppuninitialvec}
  %% \input{cppnote-uninitialized-containers.cut}
\end{numberedframe}

\begin{numberedframe}{Atomic updates}
  Pragma \lstinline{atomic} only works for simple cases.
  Can you atomically do more complicated updates?
  \begin{itemize}
  \item Make an object that has data plus a lock;
  \item Overload arithmetic operator.
  \end{itemize}
\end{numberedframe}

\begin{numberedframe}{Atomic updates: class with OMP lock}
  \begin{multicols}{2}
    \cverbatimsnippet[examples/omp/cxx/lockobject.cxx]{lockobject}
  \end{multicols}
  %%\input{cppnote-lock-inside-overloaded-operator.cut}
\end{numberedframe}

\begin{numberedframe}{Atomic updates: usage}
  \cverbatimsnippet[examples/omp/cxx/lockobject.cxx]{lockobjectuse}
\end{numberedframe}

\begin{numberedframe}{Atomic updates, comparison to native}
  Timing comparison on simplest case:
\begin{multicols}{2}
  Object with built-in lock:
\cxxverbatimsnippet{lockobjectuse}
\columnbreak
Native C++ atomics:
\cxxverbatimsnippet{atomicintuse}
\end{multicols}

  Native solution is 10x faster.

\end{numberedframe}

\begin{numberedframe}{False sharing prevention}
  \begin{lstlisting}
    #include <new>

    #ifdef __cpp_lib_hardware_interference_size
    const int spread = std::hardware_destructive_interference_size
            / sizeof(datatype);
    #else
    const int spread = 8;

    vector<datatype> k(nthreads*spread);
    #pragma omp parallel for schedule( static, 1 )
    for ( datatype i = 0; i < loops; i++ ) {
      k[ (i%nthreads) * spread ] += 2;
  \end{lstlisting}
\end{numberedframe}

\end{document}

